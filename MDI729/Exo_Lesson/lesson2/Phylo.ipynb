{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Web Scraping Wikipedia using BeautifulSoup and Python\n",
    "\n",
    "« Une théorie veut que n'importe quel article sur Wikipedia pointe au final sur la philosophie. Pour la vérifier, il suffit de cliquer sur le premier lien d'un article Wikipedia qui mène à un autre article et ainsi de suite : à force, on tombe immanquablement sur l'article dédié à la philosophie. »\n",
    "\n",
    "Ecrivons un programme qui vérifie cette théorie. Ce programme doit renvoyer la \"distance\" (int) qui sépare un article donné de l'article Philosophie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = \"https://fr.wikipedia.org/wiki/Math%C3%A9matiques\"\n",
    "end_url = \"https://fr.wikipedia.org/wiki/Philosophie\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fr.wikipedia.org/wiki/Math%C3%A9matiques\n",
      "https://fr.wikipedia.org/wiki/Connaissance\n",
      "https://fr.wikipedia.org/wiki/Notion\n",
      "https://fr.wikipedia.org/wiki/Connaissance_(philosophie)\n",
      "le lien est trouvé\n",
      "La distance parcourue entre ces 2 articles est : 4\n"
     ]
    }
   ],
   "source": [
    "def find_first_link(url):\n",
    "    response = requests.get(url) \n",
    "    html = response.text\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    content_div = soup.find(id=\"mw-content-text\").find(class_=\"mw-parser-output\")\n",
    "\n",
    "\n",
    "    next_link = None # on initialise le lien suivant à none\n",
    "\n",
    "    # Find all the direct children of content_div that are paragraphs\n",
    "    for element in content_div.find_all(\"p\", recursive=False):\n",
    "        \n",
    "       # on parcourt les éléments de la page et on cherche les liens les uns après les autres\n",
    "        \n",
    "        if element.find(\"a\", recursive=False):\n",
    "            next_link = element.find(\"a\", recursive=False).get('href')\n",
    "            break\n",
    "\n",
    "    if not next_link:\n",
    "        return\n",
    "\n",
    "    # Build a full url from the relative next_link url\n",
    "    first_link = urllib.parse.urljoin(\n",
    "        'https://fr.wikipedia.org/', next_link)\n",
    "\n",
    "    return first_link\n",
    "\n",
    "\n",
    "def continue_crawl(search_history, target_url, max_steps=30):\n",
    "    # Verifier si le lien c'est un lien vers phylosophie\n",
    "    if search_history[-1] == target_url:\n",
    "        print(\"le lien est trouvé\")\n",
    "        return False\n",
    "        # on pose une limite à la recherche\n",
    "    elif len(search_history) > max_steps:\n",
    "        print(\"La recherche a pris une longueur non raisonable superieur à 30, nous quittons la recherche!\")\n",
    "        return False\n",
    "    elif search_history[-1] in search_history[:-1]:\n",
    "        print(\"Nous avons déjà trouver cette article nous quittons la recherche\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "article_chain = [start_url]\n",
    "\n",
    "while continue_crawl(article_chain, target_url):\n",
    "    print(article_chain[-1])\n",
    "\n",
    "    first_link = find_first_link(article_chain[-1])\n",
    "    if not first_link:\n",
    "        print(\"We've arrived at an article with no links, aborting search!\")\n",
    "        break\n",
    "\n",
    "    article_chain.append(first_link)\n",
    "\n",
    "    time.sleep(2)  # Slow things down so as to not hammer Wikipedia's servers\n",
    "\n",
    "    \n",
    "print('La distance parcourue entre ces 2 articles est : ' + str(len(article_chain)-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
